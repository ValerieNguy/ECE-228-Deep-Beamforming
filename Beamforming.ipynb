{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a2e790-0f79-4a8c-bcbd-722534fe7e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: DeepMIMO==2 in /home/vtn008/.local/lib/python3.11/site-packages (2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from DeepMIMO==2) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from DeepMIMO==2) (1.13.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from DeepMIMO==2) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install DeepMIMO==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29bdae1-7529-47c7-8d20-3206b0928492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.9\n",
      "Name: tensorflow\n",
      "Version: 2.18.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /opt/conda/lib/python3.11/site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: tf_keras\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7890e0f6-ec4e-454e-bab3-2b73375ba8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no change     /opt/conda/condabin/conda\n",
      "no change     /opt/conda/bin/conda\n",
      "no change     /opt/conda/bin/conda-env\n",
      "no change     /opt/conda/bin/activate\n",
      "no change     /opt/conda/bin/deactivate\n",
      "no change     /opt/conda/etc/profile.d/conda.sh\n",
      "no change     /opt/conda/etc/fish/conf.d/conda.fish\n",
      "no change     /opt/conda/shell/condabin/Conda.psm1\n",
      "no change     /opt/conda/shell/condabin/conda-hook.ps1\n",
      "no change     /opt/conda/lib/python3.11/site-packages/xontrib/conda.xsh\n",
      "no change     /opt/conda/etc/profile.d/conda.csh\n",
      "no change     /home/vtn008/.bashrc\n",
      "No action taken.\n",
      ".     .ipynb_checkpoints\t  DLCB_code_output  O1_60      check.py\n",
      "..    Beamforming.ipynb\t\t  DLCB_dataset\t    O1_60.zip  result.png\n",
      ".git  Coordinated_Beamforming.py  LICENSE.md\t    README.md\n"
     ]
    }
   ],
   "source": [
    "!conda init\n",
    "#!source /opt/conda/bin/activate py37\n",
    "!cd /home/vtn008/\n",
    "!ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbe4bf36-74fc-4876-b26a-bdc607dadfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Deep Learning Coordinated Beamforming with DeepMIMO #################\n",
    "# Author: Umut Demirhan, Ahmed Alkhateeb\n",
    "# Date: March 19, 2022 \n",
    "# Paper: A. Alkhateeb, S. Alex, P. Varkey, Y. Li, Q. Qu and D. Tujkovic, \n",
    "# \"Deep Learning Coordinated Beamforming for Highly-Mobile Millimeter Wave \n",
    "# Systems,\" in IEEE Access, vol. 6, pp. 37328-37348, 2018.\n",
    "###########################################################################\n",
    "\n",
    "import DeepMIMO\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat, savemat \n",
    "import glob\n",
    "import re \n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 8] # Set default plot size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac90f43-30be-4acf-9a6f-2b32a9abeb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beamforming_codebook(ant_shape = np.array([1, 32, 1]), oversampling_rate = np.array([1, 1, 1]), kd = 0.5):\n",
    "    \n",
    "    kd = 2 * np.pi * kd\n",
    "    codebook_size = ant_shape * oversampling_rate\n",
    "    \n",
    "    vecs = []\n",
    "    for dim in range(3):\n",
    "        ind = np.arange(ant_shape[dim]).reshape((-1, 1))\n",
    "        codebook_ang = np.linspace(0, np.pi, codebook_size[dim], endpoint = False).reshape((1, -1))                                                                                                     \n",
    "        vec = np.sqrt(1./ant_shape[dim]) * np.exp(-1j * kd * ind * np.cos(codebook_ang))\n",
    "        vecs.append(vec)\n",
    "        \n",
    "    F = np.kron(vecs[2], np.kron(vecs[1], vecs[0]))\n",
    "    \n",
    "    return F\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ce3ec9-32e6-4146-918a-1771b6494671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OFDM': {'RX_filter': 0,\n",
      "          'bandwidth': 0.5,\n",
      "          'subcarriers': 1024,\n",
      "          'subcarriers_limit': 64,\n",
      "          'subcarriers_sampling': 1},\n",
      " 'OFDM_channels': 1,\n",
      " 'active_BS': array([3, 4]),\n",
      " 'bs_antenna': {'radiation_pattern': 'halfwave-dipole',\n",
      "                'shape': array([ 1, 32,  8]),\n",
      "                'spacing': 0.5},\n",
      " 'dataset_folder': '',\n",
      " 'dynamic_settings': {'first_scene': 1, 'last_scene': 1},\n",
      " 'enable_BS2BS': False,\n",
      " 'num_paths': 5,\n",
      " 'row_subsampling': 1,\n",
      " 'scenario': 'O1_60',\n",
      " 'ue_antenna': {'radiation_pattern': 'halfwave-dipole',\n",
      "                'shape': array([1, 1, 1]),\n",
      "                'spacing': 0.5},\n",
      " 'user_row_first': 1000,\n",
      " 'user_row_last': 1300,\n",
      " 'user_subsampling': 1}\n"
     ]
    }
   ],
   "source": [
    "#%% # Generate the dataset\n",
    "# # Load and print the default parameters\n",
    "parameters = DeepMIMO.default_params()\n",
    "\n",
    "\n",
    "# # Change parameters for the setup\n",
    "# Scenario O1_60 extracted at the dataset_folder\n",
    "parameters['scenario'] = 'O1_60'\n",
    "parameters['dataset_folder'] = '' # Set DeepMIMO dataset folder that has O1_60\n",
    "\n",
    "parameters['num_paths'] = 5\n",
    "\n",
    "# User rows 1-100\n",
    "parameters['user_row_first'] = 1000\n",
    "parameters['user_row_last'] = 1300\n",
    "\n",
    "# Activate only the first basestation\n",
    "#parameters['active_BS'] = np.array([3, 4, 5, 6]) \n",
    "\n",
    "parameters['active_BS'] = np.array([3, 4]) \n",
    "\n",
    "\n",
    "parameters['OFDM']['bandwidth'] = 0.5 # 50 MHz\n",
    "parameters['OFDM']['subcarriers'] = 1024 # OFDM with 512 subcarriers\n",
    "parameters['OFDM']['subcarriers_limit'] = 64 # Keep only first 64 subcarriers\n",
    "\n",
    "parameters['enable_BS2BS'] = False\n",
    "\n",
    "parameters['ue_antenna']['shape'] = np.array([1, 1, 1]) # Single antenna\n",
    "parameters['bs_antenna']['shape'] = np.array([1, 32, 8]) # ULA of 32 elements\n",
    "parameters['bs_antenna']['radiation_pattern'] = 'halfwave-dipole'\n",
    "parameters['ue_antenna']['radiation_pattern'] = 'halfwave-dipole'\n",
    "pprint(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d371ce-7582-463f-af63-c2a6b0a56449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 3\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 235300/235300 [00:10<00:00, 23218.41it/s]\n",
      "Generating channels: 100%|██████████| 54481/54481 [00:31<00:00, 1740.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basestation 4\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 235300/235300 [00:10<00:00, 23390.53it/s]\n",
      "Generating channels: 100%|██████████| 54481/54481 [00:28<00:00, 1920.07it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = DeepMIMO.generate_data(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6875718d-aa9f-400c-be8d-5f0eab637b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Parameters and Codebook\n",
    "F = beamforming_codebook(ant_shape = parameters['bs_antenna'][0]['shape'], oversampling_rate = np.array([1, 2, 1]), kd = parameters['bs_antenna'][0]['spacing'])\n",
    "\n",
    "num_OFDM = int(parameters['OFDM']['subcarriers_limit']/parameters['OFDM']['subcarriers_sampling'])\n",
    "num_beams = F.shape[1]\n",
    "num_bs = len(parameters['active_BS'])\n",
    "num_ue = len(parameters['active_UE'])\n",
    "\n",
    "\n",
    "\n",
    "NF = 5             # Noise figure at the base station\n",
    "Process_Gain = 10  # Channel estimation processing gain\n",
    "BW = parameters['OFDM']['bandwidth'] * 1e9 # System bandwidth in Hz\n",
    "noise_power_dB = -204 + 10*np.log10(BW/parameters['OFDM']['subcarriers']) + NF - Process_Gain; # Noise power in dB\n",
    "noise_power = 10**(.1*(noise_power_dB)); # Noise power\n",
    "\n",
    "#%% DL Input-Output\n",
    "input_norm = np.zeros((num_bs, num_ue, num_OFDM), dtype=complex)\n",
    "max_rates = np.zeros((num_bs, num_ue, num_beams))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0288e823-67bd-4a91-805d-94b6dec99d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neural Network Input-Output Generation-BS-0: 100%|██████████| 54481/54481 [42:37<00:00, 21.30it/s]  \n",
      "Neural Network Input-Output Generation-BS-1: 100%|██████████| 54481/54481 [33:09<00:00, 27.38it/s]  \n",
      "Neural Network Input-Output Generation-BS: 100%|██████████| 2/2 [1:15:47<00:00, 2273.64s/it]\n"
     ]
    }
   ],
   "source": [
    "#for bs_idx in tqdm(range(num_bs), desc='Neural Network Input-Output Generation-BS', position=0, leave=True):\n",
    "\n",
    "for bs_idx in tqdm(range(num_bs), desc='Neural Network Input-Output Generation-BS', position=0, leave=True):\n",
    "    for ue_idx in tqdm(range(num_ue), desc='Neural Network Input-Output Generation-BS-%i'%bs_idx, position=0, leave=True):\n",
    "        ch = dataset[bs_idx]['user']['channel'][ue_idx].squeeze()\n",
    "        ch = ch + np.sqrt(noise_power) * (np.random.randn(*(ch.shape)) + 1j * np.random.randn(*(ch.shape)))\n",
    "        input_norm[bs_idx, ue_idx, :] = ch[0, :]\n",
    "        max_rates[bs_idx, ue_idx, :] = np.sum(np.log2(1 + np.abs(ch.T.conj() @ F)**2),  axis = 0)/num_OFDM\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2946bde8-f143-4b6e-af23-dac44db64c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input reshape - normalize\n",
    "input_norm = np.transpose(input_norm, axes=[1, 0, 2])\n",
    "input_norm = input_norm.reshape((num_ue, -1))\n",
    "input_norm /=  np.amax(np.abs(input_norm))\n",
    "\n",
    "# Output reshape - normalize\n",
    "max_rates_norm_factor = np.amax(max_rates, axis=2, keepdims=True)\n",
    "max_rates_norm_factor[max_rates_norm_factor== 0] = 1 # Do not normalize if all zeros\n",
    "max_rates /= max_rates_norm_factor\n",
    "max_rates = np.transpose(max_rates, axes=[1, 0, 2])\n",
    "max_rates = max_rates.reshape((num_ue, -1))\n",
    "\n",
    "if not os.path.exists('./DLCB_dataset'):\n",
    "                      os.makedirs('DLCB_dataset')\n",
    "savemat('./DLCB_dataset/DLCB_input.mat', {'DL_input': input_norm})\n",
    "savemat('./DLCB_dataset/DLCB_output.mat', {'DL_output': max_rates})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6ec4e68-c9c3-44fd-abb4-3a7c19d75a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 02:42:06.282509: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747968126.308056     661 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747968126.315410     661 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-23 02:42:06.342146: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# %% Machine Learning\n",
    "import os\n",
    "import keras\n",
    "import keras.models as models\n",
    "from keras.layers import Dense,Dropout\n",
    "import numpy as np\n",
    "\n",
    "# Model training function\n",
    "def train(In_train, Out_train, In_test, Out_test,\n",
    "          epochs, batch_size,dr,\n",
    "          num_hidden_layers, nodes_per_layer,\n",
    "          loss_fn,n_BS,n_beams):\n",
    "    \n",
    "    in_shp = list(In_train.shape[1:])\n",
    "\n",
    "    AP_models = []\n",
    "    for bs_idx in range(n_BS):\n",
    "        idx_str = 'BS%i' % bs_idx\n",
    "        idx = bs_idx*n_beams\n",
    "        \n",
    "        model = models.Sequential()\n",
    "        model.add(Dense(nodes_per_layer, activation='relu', kernel_initializer='he_normal', input_shape=in_shp))\n",
    "        model.add(Dropout(dr))\n",
    "        for h in range(num_hidden_layers):\n",
    "            model.add(Dense(nodes_per_layer, activation='relu', kernel_initializer='he_normal'))\n",
    "            model.add(Dropout(dr))\n",
    "        \n",
    "        model.add(Dense(n_beams, activation='relu', kernel_initializer='he_normal',\n",
    "                  name=\"dense\" + idx_str + \"o\"))\n",
    "        model.compile(loss=loss_fn, optimizer='adam')\n",
    "        model.summary()\n",
    "\n",
    "        print(Out_train[:, idx:idx + n_beams].shape)\n",
    "        model.fit(In_train,\n",
    "                    Out_train[:, idx:idx + n_beams],\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=2,\n",
    "                    validation_data=(In_test, Out_test[:,idx:idx + n_beams]),\n",
    "                    callbacks = [\n",
    "                        #keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n",
    "                        keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "                    ])\n",
    "        \n",
    "        AP_models.append(model)\n",
    "        \n",
    "        \n",
    "    return AP_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e9eb56-fae9-4794-95f6-798a05a9938a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loadmat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Reading input and output sets generated from MATLAB\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m In_set_file\u001b[38;5;241m=\u001b[39m\u001b[43mloadmat\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDLCB_dataset/DLCB_input.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m Out_set_file\u001b[38;5;241m=\u001b[39mloadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDLCB_dataset/DLCB_output.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m In_set\u001b[38;5;241m=\u001b[39mIn_set_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDL_input\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loadmat' is not defined"
     ]
    }
   ],
   "source": [
    "# Reading input and output sets generated from MATLAB\n",
    "In_set_file=loadmat('DLCB_dataset/DLCB_input.mat')\n",
    "Out_set_file=loadmat('DLCB_dataset/DLCB_output.mat')\n",
    "\n",
    "In_set=In_set_file['DL_input']\n",
    "Out_set=Out_set_file['DL_output']\n",
    "\n",
    "# Parameter initialization\n",
    "num_user_tot=In_set.shape[0]\n",
    "n_DL_size=[0.001, .05, .1, .15, .2, .25, .3, .35, .4, .45, .5, .55, .6, .65, .7]\n",
    "count=0\n",
    "num_tot_TX=2\n",
    "num_beams=512\n",
    "\n",
    "for DL_size_ratio in n_DL_size:\n",
    "    \n",
    "    print (DL_size_ratio)\n",
    "    count=count+1\n",
    "    DL_size=int(num_user_tot*DL_size_ratio)\n",
    "    \n",
    "    np.random.seed(2016)\n",
    "    n_examples = DL_size\n",
    "    num_train  = int(DL_size * 0.8)\n",
    "    num_test   = int(num_user_tot*.2)\n",
    "    \n",
    "    train_index = np.random.choice(range(0,num_user_tot), size=num_train, replace=False)\n",
    "    rem_index = set(range(0,num_user_tot))-set(train_index)\n",
    "    test_index= list(set(np.random.choice(list(rem_index), size=num_test, replace=False)))\n",
    "    \n",
    "    In_train = In_set[train_index]\n",
    "    In_test =  In_set[test_index] \n",
    "        \n",
    "    Out_train = Out_set[train_index]\n",
    "    Out_test = Out_set[test_index]\n",
    "    \n",
    "    \n",
    "    # Learning model parameters\n",
    "    epochs = 10     \n",
    "    batch_size = 100  \n",
    "    dr = 0.05                  # dropout rate  \n",
    "    num_hidden_layers=4\n",
    "    nodes_per_layer=In_train.shape[1]\n",
    "    loss_fn='mean_squared_error'\n",
    "    \n",
    "    # Model training\n",
    "    AP_models = train(In_train, Out_train, In_test, Out_test,\n",
    "                                          epochs, batch_size,dr,\n",
    "                                          num_hidden_layers, nodes_per_layer,\n",
    "                                          loss_fn,num_tot_TX,num_beams)\n",
    "\n",
    "    \n",
    "    # Model running/testing\n",
    "    DL_Result={}\n",
    "    for idx in range(0,num_tot_TX,1): \n",
    "        beams_predicted=AP_models[idx].predict( In_test, batch_size=10, verbose=0)\n",
    "    \n",
    "        DL_Result['TX'+str(idx+1)+'Pred_Beams']=beams_predicted\n",
    "        DL_Result['TX'+str(idx+1)+'Opt_Beams']=Out_test[:,idx*num_beams:(idx+1)*num_beams]\n",
    "\n",
    "    DL_Result['user_index']=test_index\n",
    "    \n",
    "    \n",
    "    if not os.path.exists('./DLCB_code_output'):\n",
    "                          os.makedirs('DLCB_code_output')\n",
    "    savemat('DLCB_code_output/DL_Result'+str(count)+'.mat',DL_Result)\n",
    "\n",
    "#%% Read Results\n",
    "file_list = sorted(glob.glob('DLCB_code_output/DL_Result*'), key=lambda x: int(re.findall(r'\\d+', x)[0]))\n",
    "num_files = len(file_list)\n",
    "\n",
    "user_index = []\n",
    "pred_beams = []\n",
    "opt_beams = []\n",
    "for file in tqdm(file_list, desc='Reading DL results'):\n",
    "    matfile = loadmat(file)\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    for idx in range(num_bs):\n",
    "        l1.append(matfile['TX'+str(idx+1)+'Pred_Beams'])\n",
    "        l2.append(matfile['TX'+str(idx+1)+'Opt_Beams'])\n",
    "        \n",
    "    pred_beams.append(l1)\n",
    "    opt_beams.append(l2)\n",
    "    user_index.append(matfile['user_index'])\n",
    "\n",
    "\n",
    "Pn = -204 + 10*np.log10(BW) # Noise power in dB\n",
    "SNR = 10**(.1*(0-Pn))\n",
    "\n",
    "ach_rate_DL = np.zeros(num_files)\n",
    "ach_rate_opt = np.zeros(num_files)\n",
    "\n",
    "eff_rate = np.zeros(num_files)\n",
    "opt_rate = np.zeros(num_files)\n",
    "for file_idx in tqdm(np.arange(num_files), desc = 'Calculating results'):\n",
    "    user_index_file = user_index[file_idx].flatten()\n",
    "    for ue_idx in range(len(user_index_file)):\n",
    "        eff_ch = []\n",
    "        opt_ch = []\n",
    "        for bs_idx in range(num_bs):\n",
    "            if file_idx == 0: # Random BF - 0 Samples\n",
    "                pred_beam_idx = np.random.randint(num_beams)\n",
    "            else:\n",
    "                pred_beam_idx = np.argmax(pred_beams[file_idx][bs_idx][ue_idx])\n",
    "            opt_beam_idx = np.argmax(opt_beams[file_idx][bs_idx][ue_idx])\n",
    "            ch_single_bs = dataset[bs_idx]['user']['channel'][user_index_file[ue_idx]].squeeze()\n",
    "            eff_ch_single_pred = ch_single_bs.T.conj() @ F[:, pred_beam_idx]\n",
    "            opt_ch_single_pred = ch_single_bs.T.conj() @ F[:, opt_beam_idx]\n",
    "            eff_ch.append(eff_ch_single_pred)\n",
    "            opt_ch.append(opt_ch_single_pred)\n",
    "        eff_ch = np.array(eff_ch)\n",
    "        opt_ch = np.array(opt_ch)\n",
    "        eff_rate[file_idx] += np.sum(np.log2(1 + SNR * np.abs(np.diag(eff_ch.conj().T @ eff_ch))))\n",
    "        opt_rate[file_idx] += np.sum(np.log2(1 + SNR * np.abs(np.diag(opt_ch.conj().T @ opt_ch))))\n",
    "    eff_rate[file_idx] /= len(user_index_file)*num_OFDM\n",
    "    opt_rate[file_idx] /= len(user_index_file)*num_OFDM\n",
    "\n",
    "\n",
    "# % Eff achievable rate calculations\n",
    "theta_user=(102/parameters['bs_antenna'][0]['shape'][1])*np.pi/180\n",
    "alpha=60*np.pi/180\n",
    "distance_user=10\n",
    "Tc_const=(distance_user*theta_user)/(2*np.sin(alpha)) # ms\n",
    "Tt=10*1e-6; # ms\n",
    "\n",
    "v_mph=50\n",
    "v=v_mph*1000*1.6/3600 # m/s\n",
    "Tc=Tc_const/v\n",
    "\n",
    "overhead_opt=1-(num_beams*Tt)/Tc # overhead of beam training\n",
    "overhead_DL=1-Tt/Tc # overhead of proposed DL method\n",
    "\n",
    "#%% Plotting the figure\n",
    "DL_size_array=np.arange(0, 2.5*(num_files), 2.5);\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(DL_size_array, opt_rate, '--k', label = 'Genie-aided Coordinated Beamforming')\n",
    "plt.plot(DL_size_array, eff_rate*overhead_DL, '-bo', label = 'Deep Learning Coordinated Beamforming')\n",
    "plt.plot(DL_size_array, opt_rate*overhead_opt, '-rs', label = 'Baseline Coordinated Beamforming')\n",
    "plt.ylim([0, 6])\n",
    "plt.minorticks_on()\n",
    "plt.grid()\n",
    "plt.xlabel('Deep Learning Dataset Size (Thousand Samples)')\n",
    "plt.ylabel('Achievable Rate (bps/Hz)')\n",
    "plt.legend()\n",
    "plt.savefig('result.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5883cd01-88dc-404e-8fdc-684616e5ac48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8fa65-46cb-45f9-9488-67fec229854b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1098a140-af6b-4bd4-8d0d-f634ce986b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4055d26-b0dd-4fc4-9a74-435e7713f6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ef130-17cb-4929-918f-fd0288b38b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
